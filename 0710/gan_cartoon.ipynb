{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用昨天的卡通資料集來練GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, UpSampling2D, Dense, Flatten, Input, BatchNormalization, Reshape, LeakyReLU, Conv2DTranspose, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, folder_path, img_size):\n",
    "        self.folder_path = folder_path\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.path_list = glob(folder_path) # 讀取資料夾全部圖片路徑\n",
    "        assert len(self.path_list) > 0, 'path not existed!'\n",
    "    \n",
    "    def __imread(self, img_path):\n",
    "        '''讀取圖片'''\n",
    "        return np.array(Image.open(img_path).convert('RGB').resize(self.img_size[:-1], Image.ANTIALIAS))\n",
    "    \n",
    "    def sampling_data(self, batch_size, shuffle=True):\n",
    "        img_path_list = self.path_list\n",
    "        \n",
    "        if shuffle:\n",
    "            random.shuffle(img_path_list)\n",
    "            \n",
    "        for batch_idx in range(0, len(img_path_list), batch_size):\n",
    "            path_set = img_path_list[batch_idx : batch_idx + batch_size]\n",
    "            \n",
    "            # 預設空間，避免 append很慢\n",
    "            img_set = np.zeros((len(path_set),) + self.img_size)\n",
    "            for img_idx, path in enumerate(path_set):\n",
    "                img_set[img_idx] = self.__imread(path)\n",
    "            \n",
    "            # 127.5是255的一半，一到負一之間\n",
    "            img_set = img_set / 127.5 - 1\n",
    "            # 暫停\n",
    "            yield img_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader('../0709/Preview/cartoon/*.png', (32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x213c8e5ffd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "next_one = next(data.sampling_data(1))\n",
    "# 強制變回 0到 1\n",
    "plt.imshow(next_one[0]*.5+.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_one[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, noise_dim, img_size=(64, 64, 3)):\n",
    "        self.noise_dim = noise_dim # noise_dim = 雜訊維度\n",
    "        self.img_size = img_size # img_size = 圖片大小\n",
    "        self.dataloader = DataLoader('../0709/Preview/cartoon/*.png', self.img_size)\n",
    "        \n",
    "    def build_generator(self):\n",
    "        noise_input = Input(shape=(self.noise_dim,))\n",
    "        \n",
    "        # 首先，將輸入轉換為 4x4 128通道的 feature map\n",
    "        x = Dense(64 * 4 * 4)(noise_input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Reshape((4, 4, 64))(x)\n",
    "\n",
    "        # Transpose的效果在 G會比 conv + unpooling差，keras會去參考以前的 conv參數\n",
    "#         x = Conv2DTranspose(1024, 3, strides=2, padding='same')(x)\n",
    "        x = Conv2D(1024, kernel_size=4, padding=\"same\")(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "        # 上取樣至 16 x 16\n",
    "#         x = Conv2DTranspose(512, 4, strides=2, padding='same')(x)\n",
    "        x = Conv2D(512, kernel_size=4, padding=\"same\")(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        \n",
    "#         x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "        x = Conv2D(256, kernel_size=4, padding=\"same\")(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        \n",
    "#         x = Conv2DTranspose(128, 4, strides=2, padding='same')(x)\n",
    "        x = Conv2D(128, kernel_size=4, padding=\"same\")(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "        # 生成一個 64x64 3-channel 的feature map\n",
    "        img = Conv2D(self.img_size[2], 7, activation='tanh', padding='same')(x)\n",
    "        generator = Model(noise_input, img)\n",
    "#         generator.summary()\n",
    "        return generator\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        img_input = Input(shape=self.img_size)\n",
    "        \n",
    "        x = Conv2D(256, 4, strides=2)(img_input)\n",
    "#         x = Dropout(0.25)(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "        x = Conv2D(256, 4, strides=2)(x)\n",
    "#         x = Dropout(0.25)(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        \n",
    "        x = Conv2D(128, 4, strides=2)(x)\n",
    "#         x = Dropout(0.25)(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        \n",
    "        x = Conv2D(128, 4, strides=2)(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        # 重要的技巧（新增一個dropout層）\n",
    "        x = Dropout(0.4)(x)\n",
    "\n",
    "        # 分類層\n",
    "        validity = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        discriminator = Model(img_input, validity)\n",
    "#         discriminator.summary()\n",
    "        return discriminator\n",
    "\n",
    "    def connect(self):\n",
    "        self.generator = self.build_generator()\n",
    "        print(self.generator.count_params())\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        print(self.discriminator.count_params())\n",
    "        self.optimizer = Adam(.0002, .5)\n",
    "        # Optimizer用Adam, Learning rate=0.0001~0.0002, 切勿調高\n",
    "        self.discriminator.compile(optimizer=self.optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "        \n",
    "        noise = Input(shape=(self.noise_dim,))\n",
    "        img = self.generator(noise)\n",
    "        self.discriminator.trainable = False # 在訓練G時, 鎖定D\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        self.combined = Model(noise, validity)\n",
    "        self.combined.compile(optimizer=self.optimizer, loss='binary_crossentropy')\n",
    "\n",
    "    def train(self, epochs, batch_size, sample_interval=200):\n",
    "        self.history = []\n",
    "        valid = np.ones((batch_size, 1)) # 1 = 真實圖片\n",
    "        fake = np.zeros((batch_size, 1)) # 0 = 生成圖片\n",
    "\n",
    "        for e in range(epochs):\n",
    "            for i, real_img in enumerate(self.dataloader.sampling_data(batch_size)):\n",
    "                # Train D\n",
    "                noise = np.random.standard_normal((batch_size, self.noise_dim))\n",
    "                fake_img = self.generator.predict(noise)\n",
    "\n",
    "                d_loss_real, real_acc = self.discriminator.train_on_batch(real_img, valid[:len(real_img)])\n",
    "                d_loss_fake, fake_acc = self.discriminator.train_on_batch(fake_img, fake)\n",
    "                d_loss = .5 * (d_loss_real + d_loss_fake)\n",
    "                d_acc = .5 * (real_acc + fake_acc)\n",
    "                                                                          \n",
    "                # Train G\n",
    "                noise = np.random.standard_normal((batch_size, self.noise_dim))\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                if i % sample_interval == 0:\n",
    "                    info = {\n",
    "                            'epoch': e,\n",
    "                            'iter': i,\n",
    "                            'd_loss': d_loss,\n",
    "                            'd_acc': d_acc*100,\n",
    "                            'g_loss': g_loss\n",
    "                            }\n",
    "                    self.history.append(list(info.values()))\n",
    "                    print('[Epoch %(epoch)d][Iteration %(iter)d][D loss: %(d_loss).6f, acc: %(d_acc).2f%%][G loss: %(g_loss).6f]' % info)\n",
    "            self.__sample_image(e)\n",
    "        return self.history\n",
    "\n",
    "    def __sample_image(self, epoch):\n",
    "        r, c = 8, 8 # 列, 欄\n",
    "        noise = np.random.standard_normal((r*c, self.noise_dim))\n",
    "        img = self.generator.predict(noise).reshape((r, c) + self.img_size)\n",
    "        img = img * .5 + .5\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        axs = fig.subplots(r, c)\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(img[i, j])\n",
    "                axs[i, j].axis('off')\n",
    "        fig.savefig('./Image/%5d.png' % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0713 18:54:12.083514 11368 deprecation_wrapper.py:119] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0713 18:54:12.093515 11368 deprecation_wrapper.py:119] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0713 18:54:12.094515 11368 deprecation_wrapper.py:119] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0713 18:54:12.142513 11368 deprecation_wrapper.py:119] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0713 18:54:12.164513 11368 deprecation_wrapper.py:119] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0713 18:54:12.172517 11368 deprecation_wrapper.py:119] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0713 18:54:13.222275 11368 deprecation_wrapper.py:119] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12223235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 18:54:13.646306 11368 deprecation.py:506] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0713 18:54:13.669275 11368 deprecation_wrapper.py:119] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0713 18:54:13.674276 11368 deprecation.py:323] From c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Iteration 0][D loss: 0.873152, acc: 48.44%][G loss: 1.784429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Iteration 10][D loss: 0.677731, acc: 63.28%][G loss: 1.300054]\n",
      "[Epoch 0][Iteration 20][D loss: 0.514959, acc: 69.53%][G loss: 1.962628]\n",
      "[Epoch 0][Iteration 30][D loss: 0.048724, acc: 100.00%][G loss: 3.231112]\n",
      "[Epoch 0][Iteration 40][D loss: 0.818018, acc: 60.94%][G loss: 0.874213]\n",
      "[Epoch 0][Iteration 50][D loss: 0.159231, acc: 96.09%][G loss: 1.557415]\n",
      "[Epoch 0][Iteration 60][D loss: 0.159541, acc: 95.31%][G loss: 1.782186]\n",
      "[Epoch 0][Iteration 70][D loss: 0.073855, acc: 99.22%][G loss: 2.655332]\n",
      "[Epoch 0][Iteration 80][D loss: 0.023491, acc: 100.00%][G loss: 3.629838]\n",
      "[Epoch 0][Iteration 90][D loss: 0.092758, acc: 98.44%][G loss: 2.737280]\n",
      "[Epoch 0][Iteration 100][D loss: 0.100758, acc: 98.44%][G loss: 2.530564]\n",
      "[Epoch 0][Iteration 110][D loss: 0.153019, acc: 96.09%][G loss: 2.250159]\n",
      "[Epoch 0][Iteration 120][D loss: 0.105975, acc: 97.66%][G loss: 2.606342]\n",
      "[Epoch 0][Iteration 130][D loss: 0.074674, acc: 100.00%][G loss: 2.596578]\n",
      "[Epoch 0][Iteration 140][D loss: 0.078287, acc: 98.44%][G loss: 2.833672]\n",
      "[Epoch 0][Iteration 150][D loss: 0.065657, acc: 100.00%][G loss: 2.808042]\n",
      "[Epoch 1][Iteration 0][D loss: 0.066348, acc: 100.00%][G loss: 2.489740]\n",
      "[Epoch 1][Iteration 10][D loss: 0.041307, acc: 100.00%][G loss: 3.417351]\n",
      "[Epoch 1][Iteration 20][D loss: 0.047878, acc: 100.00%][G loss: 3.115432]\n",
      "[Epoch 1][Iteration 30][D loss: 0.042702, acc: 100.00%][G loss: 3.204453]\n",
      "[Epoch 1][Iteration 40][D loss: 0.029755, acc: 100.00%][G loss: 3.457177]\n",
      "[Epoch 1][Iteration 50][D loss: 0.030721, acc: 100.00%][G loss: 3.419755]\n",
      "[Epoch 1][Iteration 60][D loss: 0.036116, acc: 99.22%][G loss: 3.352031]\n",
      "[Epoch 1][Iteration 70][D loss: 0.019523, acc: 100.00%][G loss: 3.736768]\n",
      "[Epoch 1][Iteration 80][D loss: 0.027152, acc: 100.00%][G loss: 3.825319]\n",
      "[Epoch 1][Iteration 90][D loss: 0.021030, acc: 100.00%][G loss: 3.817260]\n",
      "[Epoch 1][Iteration 100][D loss: 0.031150, acc: 100.00%][G loss: 3.399414]\n",
      "[Epoch 1][Iteration 110][D loss: 0.018262, acc: 100.00%][G loss: 3.811465]\n",
      "[Epoch 1][Iteration 120][D loss: 0.038397, acc: 100.00%][G loss: 2.681835]\n",
      "[Epoch 1][Iteration 130][D loss: 0.045199, acc: 99.22%][G loss: 3.531421]\n",
      "[Epoch 1][Iteration 140][D loss: 0.012561, acc: 100.00%][G loss: 2.344804]\n",
      "[Epoch 1][Iteration 150][D loss: 0.098434, acc: 100.00%][G loss: 3.016786]\n",
      "[Epoch 2][Iteration 0][D loss: 0.045316, acc: 100.00%][G loss: 3.818219]\n",
      "[Epoch 2][Iteration 10][D loss: 0.090684, acc: 100.00%][G loss: 1.894788]\n",
      "[Epoch 2][Iteration 20][D loss: 0.116181, acc: 100.00%][G loss: 2.463255]\n",
      "[Epoch 2][Iteration 30][D loss: 0.056961, acc: 100.00%][G loss: 2.326015]\n",
      "[Epoch 2][Iteration 40][D loss: 0.083639, acc: 100.00%][G loss: 2.454593]\n",
      "[Epoch 2][Iteration 50][D loss: 0.090537, acc: 100.00%][G loss: 2.399455]\n",
      "[Epoch 2][Iteration 60][D loss: 0.045560, acc: 100.00%][G loss: 2.185079]\n",
      "[Epoch 2][Iteration 70][D loss: 0.113814, acc: 100.00%][G loss: 1.454262]\n",
      "[Epoch 2][Iteration 80][D loss: 0.122655, acc: 100.00%][G loss: 1.540858]\n",
      "[Epoch 2][Iteration 90][D loss: 0.109953, acc: 100.00%][G loss: 1.641076]\n",
      "[Epoch 2][Iteration 100][D loss: 0.101180, acc: 100.00%][G loss: 1.729142]\n",
      "[Epoch 2][Iteration 110][D loss: 0.090737, acc: 100.00%][G loss: 1.809013]\n",
      "[Epoch 2][Iteration 120][D loss: 0.082709, acc: 100.00%][G loss: 1.907260]\n",
      "[Epoch 2][Iteration 130][D loss: 0.076721, acc: 100.00%][G loss: 1.965181]\n",
      "[Epoch 2][Iteration 140][D loss: 0.070873, acc: 100.00%][G loss: 2.041349]\n",
      "[Epoch 2][Iteration 150][D loss: 0.062879, acc: 100.00%][G loss: 2.104940]\n",
      "[Epoch 3][Iteration 0][D loss: 0.061560, acc: 100.00%][G loss: 2.178929]\n",
      "[Epoch 3][Iteration 10][D loss: 0.057181, acc: 100.00%][G loss: 2.220605]\n",
      "[Epoch 3][Iteration 20][D loss: 0.053372, acc: 100.00%][G loss: 2.270338]\n",
      "[Epoch 3][Iteration 30][D loss: 0.051059, acc: 100.00%][G loss: 2.394055]\n",
      "[Epoch 3][Iteration 40][D loss: 0.046388, acc: 100.00%][G loss: 2.410216]\n",
      "[Epoch 3][Iteration 50][D loss: 0.044447, acc: 100.00%][G loss: 2.472255]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-2edcfb911371>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_img\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                 \u001b[1;31m# Train D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandard_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e650c8f60b06>\u001b[0m in \u001b[0;36msampling_data\u001b[1;34m(self, batch_size, shuffle)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mimg_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mimg_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mimg_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# 127.5是255的一半，一到負一之間\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e650c8f60b06>\u001b[0m in \u001b[0;36m__imread\u001b[1;34m(self, img_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;34m'''讀取圖片'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msampling_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    932\u001b[0m         \"\"\"\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wade\\.virtualenvs\\19'_summer_vacation-ib8vnh7u\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gan = GAN(128, img_size=(64, 64, 3))\n",
    "gan.connect()\n",
    "gan.train(10, 64, sample_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
